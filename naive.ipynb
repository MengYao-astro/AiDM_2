{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AiDM Assignment 2 - LSH for the Netflix data\n",
    "## Naive method - Time esitimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "First of all, we load in the data of approximately 103,703 users and the movies they watched among 17,770 movies in total. The first column gives the user IDs and the second column gives the movies IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading time =  0.37735605239868164 sec\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "time0 = time.time() # record the starting time of loading part.\n",
    "data_origin = np.load('../user_movie.npy')\n",
    "loading_time = time.time() - time0     # calculate the time of this part.\n",
    "print('loading time = ',loading_time,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As wee can see here, our loading process took about 0.35 second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and calculate the similarities\n",
    "Theoretically, This naive algorithm consists of two parts. Firstly, we would like to make a movie set for every single user and then put them in to a list. Secondly, for each user's movie set, we compare it with another user's. Moreover, we would like to reduce the number of operitions in simularities calculation part. To be specific, we convert 'movies watched by every user' list to sets during generating the list. We also get the length of every set and save them in order not to meassure them evey time in a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list(data,n):\n",
    "    '''\n",
    "    The function is to generate a list that contains sets for users. Each set is the watched movies for one user.\n",
    "    data :\n",
    "    n : persent of dataset will be considered\n",
    "    '''\n",
    "    data_n_persent = data[0:int(len(data_origin)*n),:] # Drag out n persent from the entire dataset.\n",
    "    user_movie_list = [[] for _ in range(len(set(data_n_persent[:,0])))] \n",
    "    # Prepare a list of sets.\n",
    "    # Every set represent a user  \n",
    "    for i in range(len(data_n_persent)):\n",
    "        user_movie_list[data_n_persent[i,0]].append(data_n_persent[i,1])\n",
    "    for j in range(len(user_movie_list)):\n",
    "        user_movie_list[j] = set(user_movie_list[j]) # convert every user list to a set\n",
    "    return user_movie_list  # will return the whole watched movies set for every user in only one list.\n",
    "    \n",
    "\n",
    "def simi(set_list):\n",
    "    '''\n",
    "    This function is to calculate the similarities between users.\n",
    "    Similarity = intersenction / union\n",
    "    set_list : \n",
    "    \n",
    "    '''\n",
    "    lengths = np.zeros(len(set_list)) # len() all of the set first.\n",
    "    for i in range(len(set_list)):\n",
    "        lengths[i] = len(set_list[i])\n",
    "        \n",
    "    similarities = np.zeros(len(set_list)) # Prepare an np array for saving the value of similarities.\n",
    "    for j in range(len(set_list)):\n",
    "        intersection = set_list[0] & set_list[i] # Use logical and to achieve the intersection\n",
    "        n_intersection = len(intersection)\n",
    "        similarities[i] = n_intersection / (lengths[0]+lengths[j] - n_intersection) # Calculate sim\n",
    "    return similarities # will return a array contains similarities between the first user and any others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record running time\n",
    "We did a test on 1 persent of the entire dataset and recorded the running time of listing and calculating the similarities separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listing time =  0.3110771179199219 sec\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()    # Record the starting point of listing process.\n",
    "set_1persent = generate_list(data_origin,0.01)\n",
    "list_time = time.time() - time1       #  Calculate the time of this part.\n",
    "print('listing time = ',list_time,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time it took to generate a list, which contains movie set of users, from 1 persent of the dataset is given above. Note that we chop out the first 1 persent of data based on rows rather than users which means the information of the last user in our test might not be completed but this issue will not affect our result of estimated time. Hence, we achieved a list consisting 1040 users' movie set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities calculating time =  0.016193866729736328 sec\n"
     ]
    }
   ],
   "source": [
    "time2 = time.time()       # Record the staring time of similarities calculation process.\n",
    "simi_1persent = simi(set_1persent)\n",
    "simi_time = time.time() - time2   # calculate the time of this part\n",
    "print('similarities calculating time = ',simi_time,'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time cost by calculating process is shown in above. The number of calculations is as the same as the number of users as we compared the first user with others ( to simplify the code, we campared the first user with himself), which is 1040."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esitimate the total  time\n",
    "Then we estimated the total time by considering 3 parts of the entire algorithm. \n",
    "\n",
    "First of all, the time cost by loading data process is fixed, which is aroud 0.25 sec. \n",
    "\n",
    "Second, the listing part is a linear opertation. Our test was making a list on 1040 users from 103,703 users. Hence, the total estimated time of second part is supposed to be about 100 times of it for our test, which is 103,703/1040 * 138.52 sec.\n",
    "\n",
    "Third, the similarities part. The time of this part is proportional to the number of calculations. In our case, we calculated 1040 similarities. The total dataset needs 103,703 * 103,702 / 2 times calculations. Therefore, we multipiled our test time by (103,703 * 103,702 /2) / 1040."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time =  0.9694272406465743  d\n"
     ]
    }
   ],
   "source": [
    "num_users = len(set(data_origin[:,0]))   # The  total number of users\n",
    "num_users_1p = len(set_1persent)         # The numbers of users in our test\n",
    "opertaions_toal = num_users * (num_users - 1) / 2.   # Total calculations \n",
    "opertaions_1p = num_users_1p                         # Calculations of our test\n",
    "op_factor = opertaions_toal / opertaions_1p\n",
    "total_time = loading_time + list_time * 100. + simi_time * op_factor    # Add them up\n",
    "print('Total time = ', total_time / 60. / 60. / 24., ' d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final result of total estimated time is about 1 day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
