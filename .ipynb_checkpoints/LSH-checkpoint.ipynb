{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AiDM Assignment 2\n",
    "##  Locality Sensitive Hashing for Netflix Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Data\n",
    "First we read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin = np.load('../user_movie.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the function for calculating the similarities between users here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list(data,n):\n",
    "    '''\n",
    "    The function is to generate a list that contains sets for users. Each set is the watched movies for one user.\n",
    "    data :\n",
    "    n : persent of dataset will be considered\n",
    "    '''\n",
    "    data_n_persent = data[0:int(len(data_origin)*n),:] # Drag out n persent from the entire dataset.\n",
    "    user_movie_list = [[] for _ in range(len(set(data_n_persent[:,0])))] \n",
    "    # Prepare a list of sets.\n",
    "    # Every set represent a user  \n",
    "    for i in range(len(data_n_persent)):\n",
    "        user_movie_list[data_n_persent[i,0]].append(data_n_persent[i,1])\n",
    "    for j in range(len(user_movie_list)):\n",
    "        user_movie_list[j] = set(user_movie_list[j]) # convert every user list to a set\n",
    "    return user_movie_list  # will return the whole watched movies set for every user in only one list.\n",
    "def simi(pair,set_list):\n",
    "    a = set_list[pair[0]]\n",
    "    b = set_list[pair[1]]\n",
    "    intersection = a & b # Use logical and to achieve the intersection\n",
    "    n_intersection = len(intersection)\n",
    "    similarity = n_intersection / (len(a) + len(b) - n_intersection) # Calculate sim\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_list_total = generate_list(data_origin,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shingling\n",
    "In the interest of memory conservation (only stoing non-zero elements) and efficient rearrangement, we store the data as ones in indicies according to their user ID (column) and rated movies (rows, 1 if rated 0 if not) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "users_movies = csc_matrix((np.ones(len(data_origin)), (data_origin[:,1], data_origin[:,0])),\\\n",
    "                          shape=(np.max(data_origin[:,1])+1, np.max(data_origin[:,0])+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signature Matrix\n",
    "Now we create a random permutations of movie indicies and rearrange our matrix to match. The first non-zero element in the new arrangement will be an element in the user's signature. We will start using 100 permutations, so that our signatures for each user are of length 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gee-whiz, it only took 441 seconds to make the signature matrix!\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "signature_length = 100\n",
    "signature_matrix = np.zeros((signature_length, np.max(data_origin[:,0])+1))\n",
    "permutation_indicies = np.arange(np.max(data_origin[:,1])+1)\n",
    "users_movies_copy = np.copy(users_movies)\n",
    "for i in range(signature_length):\n",
    "    np.random.shuffle(permutation_indicies)\n",
    "    users_movies_copy = users_movies[permutation_indicies,:]\n",
    "    signature_matrix[i,:]= (users_movies_copy!=0).argmax(axis=0)\n",
    "print('Gee-whiz, it only took', int(time.time() - tic), 'seconds to make the signature matrix!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test to make sure we made our signture matrix correctly. For the last signature in the matrix for the first user, is the index actually the first non-zero entry in the permutation_indicies arrangement?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 13214 , Entry: 0.0\n",
      "Index: 13870 , Entry: 0.0\n",
      "Index: 3710 , Entry: 0.0\n",
      "Index: 12122 , Entry: 0.0\n",
      "Index: 14324 , Entry: 0.0\n",
      "Index: 4429 , Entry: 0.0\n",
      "Index: 6805 , Entry: 0.0\n",
      "Index: 13880 , Entry: 0.0\n",
      "Index: 16174 , Entry: 0.0\n",
      "Index: 443 , Entry: 0.0\n",
      "Index: 12359 , Entry: 0.0\n",
      "Index: 7609 , Entry: 0.0\n",
      "Index: 4380 , Entry: 0.0\n",
      "Index: 11166 , Entry: 0.0\n",
      "Index: 14250 , Entry: 0.0\n",
      "Index: 5464 , Entry: 0.0\n",
      "Index: 15098 , Entry: 0.0\n",
      "Index: 8783 , Entry: 0.0\n",
      "Index: 15590 , Entry: 0.0\n",
      "Index: 9070 , Entry: 0.0\n",
      "Index: 8070 , Entry: 0.0\n",
      "Index: 14933 , Entry: 0.0\n",
      "Index: 6842 , Entry: 0.0\n",
      "Index: 14778 , Entry: 0.0\n",
      "Index: 8153 , Entry: 0.0\n",
      "Index: 9926 , Entry: 0.0\n",
      "Index: 622 , Entry: 0.0\n",
      "Index: 12261 , Entry: 0.0\n",
      "Index: 16106 , Entry: 0.0\n",
      "Index: 8025 , Entry: 0.0\n",
      "Index: 13845 , Entry: 0.0\n",
      "Index: 8043 , Entry: 0.0\n",
      "Index: 1 , Entry: 0.0\n",
      "Index: 8359 , Entry: 0.0\n",
      "Index: 10141 , Entry: 0.0\n",
      "Index: 11078 , Entry: 0.0\n",
      "Index: 12798 , Entry: 0.0\n",
      "Index: 3001 , Entry: 0.0\n",
      "Index: 6066 , Entry: 0.0\n",
      "Index: 423 , Entry: 0.0\n",
      "Index: 15507 , Entry: 0.0\n",
      "Index: 15185 , Entry: 0.0\n",
      "Index: 15937 , Entry: 0.0\n",
      "Index: 4909 , Entry: 0.0\n",
      "Index: 10526 , Entry: 0.0\n",
      "Index: 9068 , Entry: 0.0\n",
      "Index: 7761 , Entry: 1.0\n"
     ]
    }
   ],
   "source": [
    "for j in permutation_indicies[1+np.arange(int(signature_matrix[signature_length-1,0]))]:\n",
    "    print('Index:', j, ', Entry:', users_movies[j,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, that is indeed the first non-zero entry in this ordering!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Partition Into Bands\n",
    "Next we cut the signature matrix into 5 bands (to start),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_to_bucket(bands,sig_M):\n",
    "    rows = int(len(sig_M) / bands)\n",
    "    possible_sig_max = 17749\n",
    "    weight = np.arange(1,rows+1,1)\n",
    "    bucket_index_max = (1+rows)*rows/2 * possible_sig_max\n",
    "    candidate_list = [[[] for _ in range(int(bucket_index_max))] for _ in range(bands)]\n",
    "    candidates = []\n",
    "    for i in range(bands):\n",
    "        for j in range(len(sig_M[0])):\n",
    "            hash_wsum = sum(np.array(sig_M[int(i * rows):int((i+1)*rows),j]) * weight)\n",
    "            candidate_list[i][int(hash_wsum)].append(j)\n",
    "        candidates.append([x for x in candidate_list[i] if x])\n",
    "    return candidates\n",
    "\n",
    "def bucket_to_simi(candidates, Threshold ,start_time):\n",
    "    pairs = []\n",
    "    similarities = []\n",
    "    similar_users = []\n",
    "    for band in candidates:\n",
    "        for bucket in band:\n",
    "            for i in range(len(bucket)):\n",
    "                for j in np.arange(start=i+1, stop = len(bucket), step=1):\n",
    "                    pair = [bucket[i],bucket[int(j)]]\n",
    "                    if pair not in pairs:\n",
    "                        similarity = simi(pair,set_list_total)\n",
    "                        pairs.append(pair)\n",
    "                        if similarity > Threshold :\n",
    "                            similar_users.append(pair)\n",
    "                            similarities.append(similarity)\n",
    "                    if time.time() - start_time > 300:\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    return similar_users , similarities, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-6c6c9f97b9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_to_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig_M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msimilar_users\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket_to_simi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-03d566219a38>\u001b[0m in \u001b[0;36mhash_to_bucket\u001b[0;34m(bands, sig_M)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig_M\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mhash_wsum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig_M\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mcandidate_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_wsum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcandidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "       \n",
    "candidates = hash_to_bucket(bands = 25, sig_M = signature_matrix)\n",
    "similar_users , similarities , pairs = bucket_to_simi(candidates,0.5, time.time())\n",
    "\n",
    "        \n",
    "if os.path.exists('results.txt'):\n",
    "    os.remove('results.txt')\n",
    "with open('results.txt','w') as f:\n",
    "    for item in similar_users:\n",
    "        f.write('%s,%s\\n' % (item[0],item[1]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79803"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Meng's testing\n",
    "\n",
    "#candidates = set().union(candidate_list[0],candidate_list[1])\n",
    "#candidate_list[0] | candidate_list[1]\n",
    "#candidates[0] == candidates[1]\n",
    "'''\n",
    "candidates_unique = candidates[0]\n",
    "for i in range(bands-1):\n",
    "    candidates_unique += [e for e in candidates[i+1] if e not in candidates_unique]\n",
    "candidates_unique\n",
    "''''\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Michael's testing\n",
    "\n",
    "row = np.array([0, 2, 2, 0, 1, 2])\n",
    "col = np.array([0, 0, 1, 2, 2, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "A = csc_matrix((data, (row, col)), shape=(len(row), len(col))).toarray()\n",
    "print(A)\n",
    "x = np.arange(len(row))\n",
    "np.random.shuffle(x)\n",
    "print(x)\n",
    "B = A[x,:]\n",
    "print(B)\n",
    "A[0,:] = (B!=0).argmax(axis=0)\n",
    "print(A)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
